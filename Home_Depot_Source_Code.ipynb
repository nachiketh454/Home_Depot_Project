{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c915988c",
   "metadata": {},
   "source": [
    "## CSC 575 HW#4 Learning To Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa94f12",
   "metadata": {},
   "source": [
    "## 1 Loading Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d535781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# File paths\n",
    "pkl_train_x = \"C:/Users/nachi/Desktop/Info_Retrieval/Info_Assign_4/train_x.pkl\"\n",
    "pkl_train_y = \"C:/Users/nachi/Desktop/Info_Retrieval/Info_Assign_4/train_y.pkl\"\n",
    "pkl_test = \"C:/Users/nachi/Desktop/Info_Retrieval/Info_Assign_4/test.pkl\"\n",
    "\n",
    "# Load pickle files\n",
    "train_x = pd.read_pickle(pkl_train_x)\n",
    "train_y = pd.read_pickle(pkl_train_y)\n",
    "test_x = pd.read_pickle(pkl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82389220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'product_uid', 'product_title', 'search_term',\n",
       "       'product_description', 'attributes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd9731a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d794416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112067, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5753d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[angl, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[l, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>[behr, premium, textur, deckov, 1gal, sc141, t...</td>\n",
       "      <td>[deck]</td>\n",
       "      <td>[behr, premium, textur, deckov, innov, solid, ...</td>\n",
       "      <td>[applic, method, brushrollerspray, assembl, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>[delta, vero, 1handl, shower, faucet, trim, ki...</td>\n",
       "      <td>[rain, shower, head]</td>\n",
       "      <td>[updat, bathroom, delta, vero, singlehandl, sh...</td>\n",
       "      <td>[bath, faucet, type, combo, tub, shower, built...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>[delta, vero, 1handl, shower, faucet, trim, ki...</td>\n",
       "      <td>[shower, faucet]</td>\n",
       "      <td>[updat, bathroom, delta, vero, singlehandl, sh...</td>\n",
       "      <td>[bath, faucet, type, combo, tub, shower, built...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "1   3       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "2   9       100002  [behr, premium, textur, deckov, 1gal, sc141, t...   \n",
       "3  16       100005  [delta, vero, 1handl, shower, faucet, trim, ki...   \n",
       "4  17       100005  [delta, vero, 1handl, shower, faucet, trim, ki...   \n",
       "\n",
       "            search_term                                product_description  \\\n",
       "0       [angl, bracket]  [angl, make, joint, stronger, also, provid, co...   \n",
       "1          [l, bracket]  [angl, make, joint, stronger, also, provid, co...   \n",
       "2                [deck]  [behr, premium, textur, deckov, innov, solid, ...   \n",
       "3  [rain, shower, head]  [updat, bathroom, delta, vero, singlehandl, sh...   \n",
       "4      [shower, faucet]  [updat, bathroom, delta, vero, singlehandl, sh...   \n",
       "\n",
       "                                          attributes  \n",
       "0  [bullet01, versatil, connector, variou, 90, co...  \n",
       "1  [bullet01, versatil, connector, variou, 90, co...  \n",
       "2  [applic, method, brushrollerspray, assembl, de...  \n",
       "3  [bath, faucet, type, combo, tub, shower, built...  \n",
       "4  [bath, faucet, type, combo, tub, shower, built...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ad9215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.00\n",
       "1    2.50\n",
       "2    3.00\n",
       "3    2.33\n",
       "4    2.67\n",
       "Name: relevance, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b2b920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112067, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec9eaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[metal, l, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, sku, abl]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, strong, tie]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, strong, tie, hcc668]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>100003</td>\n",
       "      <td>[sterl, ensembl, 3314, x, 60, x, 7514, bath, s...</td>\n",
       "      <td>[bath, shower, kit]</td>\n",
       "      <td>[classic, architectur, meet, contemporari, des...</td>\n",
       "      <td>[builtin, flang, ye, bullet01, slightli, narro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   4       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "1   5       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "2   6       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "3   7       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "4  10       100003  [sterl, ensembl, 3314, x, 60, x, 7514, bath, s...   \n",
       "\n",
       "                      search_term  \\\n",
       "0             [metal, l, bracket]   \n",
       "1             [simpson, sku, abl]   \n",
       "2          [simpson, strong, tie]   \n",
       "3  [simpson, strong, tie, hcc668]   \n",
       "4             [bath, shower, kit]   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  [angl, make, joint, stronger, also, provid, co...   \n",
       "1  [angl, make, joint, stronger, also, provid, co...   \n",
       "2  [angl, make, joint, stronger, also, provid, co...   \n",
       "3  [angl, make, joint, stronger, also, provid, co...   \n",
       "4  [classic, architectur, meet, contemporari, des...   \n",
       "\n",
       "                                          attributes  \n",
       "0  [bullet01, versatil, connector, variou, 90, co...  \n",
       "1  [bullet01, versatil, connector, variou, 90, co...  \n",
       "2  [bullet01, versatil, connector, variou, 90, co...  \n",
       "3  [bullet01, versatil, connector, variou, 90, co...  \n",
       "4  [builtin, flang, ye, bullet01, slightli, narro...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30bf39",
   "metadata": {},
   "source": [
    "## 2. TFxIDF  Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbf6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_x['product_title'] = train_x['product_title'].apply(lambda x: ' '.join(x))\n",
    "train_x['search_term'] = train_x['search_term'].apply(lambda x: ' '.join(x))\n",
    "train_x['product_description'] = train_x['product_description'].apply(lambda x: ' '.join(x))\n",
    "train_x['attributes'] = train_x['attributes'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "test_x['product_title'] = test_x['product_title'].apply(lambda x: ' '.join(x))\n",
    "test_x['search_term'] = test_x['search_term'].apply(lambda x: ' '.join(x))\n",
    "test_x['product_description'] = test_x['product_description'].apply(lambda x: ' '.join(x))\n",
    "test_x['attributes'] = test_x['attributes'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "#We use sklearn TfidfVectorizer instance to create a vectorizer and transform both training and testing data on it. As the number of unique words is approximately around 250000, we use max features as 3000 to reduce the complexity of the problem.\n",
    "\n",
    "vect = TfidfVectorizer(max_features=1000)\n",
    "vect.fit(train_x['product_title'] + train_x['search_term'] + train_x['product_description'] + train_x['attributes'])\n",
    "\n",
    "vect_product_title = vect.transform(train_x['product_title'])\n",
    "vect_search_term = vect.transform(train_x['search_term'])\n",
    "vect_product_description = vect.transform(train_x['product_description'])\n",
    "vect_attributes = vect.transform(train_x['attributes'])\n",
    "\n",
    "#convert to array from sparse matrices\n",
    "vect_product_title = vect_product_title.toarray()\n",
    "vect_search_term = vect_search_term.toarray()\n",
    "vect_product_description = vect_product_description.toarray()\n",
    "vect_attributes = vect_attributes.toarray()\n",
    "\n",
    "#converting test data to tfidf vectors\n",
    "\n",
    "test_vect_product_title = vect.transform(test_x['product_title'])\n",
    "test_vect_search_term = vect.transform(test_x['search_term'])\n",
    "test_vect_product_description = vect.transform(test_x['product_description'])\n",
    "test_vect_attributes = vect.transform(test_x['attributes'])\n",
    "\n",
    "test_vect_product_title = test_vect_product_title.toarray()\n",
    "test_vect_search_term = test_vect_search_term.toarray()\n",
    "test_vect_product_description = test_vect_product_description.toarray()\n",
    "test_vect_attributes = test_vect_attributes.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6da22",
   "metadata": {},
   "source": [
    "## 3. Defining Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db2bc5",
   "metadata": {},
   "source": [
    "##  A. Cosine Similarity\n",
    "##  B. Jaccard Similarity\n",
    "##  C. Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b0fc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vect1,vect2):\n",
    "  \"\"\"\n",
    "  returns the cosine similarity between two vectors\n",
    "  \"\"\"\n",
    "  numerator = sum([a * b for a, b in zip(vect1, vect2)])\n",
    "  denominator = math.sqrt(sum([a ** 2 for a in vect1])) * math.sqrt(sum([b ** 2 for b in vect2]))\n",
    "  return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "def jaccard_similarity(x, y):\n",
    "    \"\"\"Returns the Jaccard similarity between two lists\"\"\"\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    if union_cardinality == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return intersection_cardinality / float(union_cardinality)\n",
    "\n",
    "def euclidean_distance(x,y):\n",
    "  \"\"\" return euclidean distance between two lists \"\"\"\n",
    "  return math.sqrt(sum(math.pow(a-b,2) for a, b in zip(x, y)))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['cosine_pt_st','cosine_pt_pd','cosine_pt_a','jaccard_pt_st','jaccard_pt_pd','jaccard_pt_a','euclidean_pt_st','euclidean_pt_pd','euclidean_pt_a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea7fc9",
   "metadata": {},
   "source": [
    "## 4. Applying Similarity Measures on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c342f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:17<00:00, 290.41it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 295.04it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 293.80it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 300.36it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 296.97it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 294.25it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 294.74it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 286.37it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 282.49it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 288.10it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 296.30it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 290.96it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 294.75it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 293.41it/s]\n",
      "100%|██████████| 4067/4067 [00:14<00:00, 289.14it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 5000\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "train_features = pd.DataFrame(columns=['cosine_st_pt','cosine_st_pd','cosine_st_a','jaccard_st_pt','jaccard_st_pd','jaccard_st_a','euclidean_st_pt','euclidean_st_pd','euclidean_st_a'])\n",
    "\n",
    "# Process the training data in chunks\n",
    "for chunk_start in range(0, len(train_x), chunk_size):\n",
    "    chunk_end = min(chunk_start + chunk_size, len(train_x))\n",
    "    chunk_train_x = train_x.iloc[chunk_start:chunk_end]\n",
    "    \n",
    "    # Compute TF-IDF vectors for the chunk\n",
    "    chunk_vect_search_term = vect.transform(chunk_train_x['search_term'])\n",
    "    chunk_vect_product_title = vect.transform(chunk_train_x['product_title'])\n",
    "    chunk_vect_product_description = vect.transform(chunk_train_x['product_description'])\n",
    "    chunk_vect_attributes = vect.transform(chunk_train_x['attributes'])\n",
    "    \n",
    "    chunk_vect_search_term = chunk_vect_search_term.toarray()\n",
    "    chunk_vect_product_title = chunk_vect_product_title.toarray()\n",
    "    chunk_vect_product_description = chunk_vect_product_description.toarray()\n",
    "    chunk_vect_attributes = chunk_vect_attributes.toarray()\n",
    "    \n",
    "    # Initialize a temporary dataframe to store features for this chunk\n",
    "    chunk_features = pd.DataFrame(columns=train_features.columns)\n",
    "    \n",
    "    # Compute features for each row in the chunk\n",
    "    for i in tqdm(range(len(chunk_train_x))):\n",
    "        cosine_st_pt = cosine_similarity(chunk_vect_search_term[i], chunk_vect_product_title[i])\n",
    "        cosine_st_pd = cosine_similarity(chunk_vect_search_term[i], chunk_vect_product_description[i])\n",
    "        cosine_st_a = cosine_similarity(chunk_vect_search_term[i], chunk_vect_attributes[i])\n",
    "        \n",
    "        jaccard_st_pt = jaccard_similarity(chunk_train_x['search_term'].iloc[i].split(), chunk_train_x['product_title'].iloc[i].split())\n",
    "        jaccard_st_pd = jaccard_similarity(chunk_train_x['search_term'].iloc[i].split(), chunk_train_x['product_description'].iloc[i].split())\n",
    "        jaccard_st_a = jaccard_similarity(chunk_train_x['search_term'].iloc[i].split(), chunk_train_x['attributes'].iloc[i].split())\n",
    "        \n",
    "        euclidean_st_pt = euclidean_distance(chunk_vect_search_term[i], chunk_vect_product_title[i])\n",
    "        euclidean_st_pd = euclidean_distance(chunk_vect_search_term[i], chunk_vect_product_description[i])\n",
    "        euclidean_st_a = euclidean_distance(chunk_vect_search_term[i], chunk_vect_attributes[i])\n",
    "        \n",
    "        chunk_features.loc[i] = [cosine_st_pt,cosine_st_pd,cosine_st_a,jaccard_st_pt,jaccard_st_pd,jaccard_st_a,euclidean_st_pt,euclidean_st_pd,euclidean_st_a]\n",
    "    \n",
    "    # Concatenate the features for this chunk with the overall features dataframe\n",
    "    train_features = pd.concat([train_features, chunk_features], axis=0)\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "test_features = pd.DataFrame(columns=['cosine_st_pt','cosine_st_pd','cosine_st_a','jaccard_st_pt','jaccard_st_pd','jaccard_st_a','euclidean_st_pt','euclidean_st_pd','euclidean_st_a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12192da",
   "metadata": {},
   "source": [
    "## 5. Applying Similarity Measures on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cdbd55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:17<00:00, 292.81it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 297.05it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 297.59it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 300.43it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 297.92it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 296.81it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 300.00it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 289.90it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 294.95it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 301.04it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 296.01it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 300.42it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 299.65it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 295.09it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 301.01it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 298.02it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 295.32it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 299.20it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 286.52it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 291.13it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 297.79it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 295.28it/s]\n",
      "100%|██████████| 2067/2067 [00:06<00:00, 297.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the test data in chunks\n",
    "for chunk_start in range(0, len(test_x), chunk_size):\n",
    "    chunk_end = min(chunk_start + chunk_size, len(test_x))\n",
    "    chunk_test_x = test_x.iloc[chunk_start:chunk_end]\n",
    "    \n",
    "    # Compute TF-IDF vectors for the chunk\n",
    "    chunk_test_vect_search_term = vect.transform(chunk_test_x['search_term'])\n",
    "    chunk_test_vect_product_title = vect.transform(chunk_test_x['product_title'])\n",
    "    chunk_test_vect_product_description = vect.transform(chunk_test_x['product_description'])\n",
    "    chunk_test_vect_attributes = vect.transform(chunk_test_x['attributes'])\n",
    "    \n",
    "    chunk_test_vect_search_term = chunk_test_vect_search_term.toarray()\n",
    "    chunk_test_vect_product_title = chunk_test_vect_product_title.toarray()\n",
    "    chunk_test_vect_product_description = chunk_test_vect_product_description.toarray()\n",
    "    chunk_test_vect_attributes = chunk_test_vect_attributes.toarray()\n",
    "    \n",
    "    # Initialize a temporary dataframe to store features for this chunk\n",
    "    chunk_features = pd.DataFrame(columns=test_features.columns)\n",
    "    \n",
    "    # Compute features for each row in the chunk\n",
    "    for i in tqdm(range(len(chunk_test_x))):\n",
    "        cosine_st_pt = cosine_similarity(chunk_test_vect_search_term[i], chunk_test_vect_product_title[i])\n",
    "        cosine_st_pd = cosine_similarity(chunk_test_vect_search_term[i], chunk_test_vect_product_description[i])\n",
    "        cosine_st_a = cosine_similarity(chunk_test_vect_search_term[i], chunk_test_vect_attributes[i])\n",
    "        \n",
    "        jaccard_st_pt = jaccard_similarity(chunk_test_x['search_term'].iloc[i].split(), chunk_test_x['product_title'].iloc[i].split())\n",
    "        jaccard_st_pd = jaccard_similarity(chunk_test_x['search_term'].iloc[i].split(), chunk_test_x['product_description'].iloc[i].split())\n",
    "        jaccard_st_a = jaccard_similarity(chunk_test_x['search_term'].iloc[i].split(), chunk_test_x['attributes'].iloc[i].split())\n",
    "        \n",
    "        euclidean_st_pt = euclidean_distance(chunk_test_vect_search_term[i], chunk_test_vect_product_title[i])\n",
    "        euclidean_st_pd = euclidean_distance(chunk_test_vect_search_term[i], chunk_test_vect_product_description[i])\n",
    "        euclidean_st_a = euclidean_distance(chunk_test_vect_search_term[i], chunk_test_vect_attributes[i])\n",
    "        \n",
    "        chunk_features.loc[i] = [cosine_st_pt,cosine_st_pd,cosine_st_a,jaccard_st_pt,jaccard_st_pd,jaccard_st_a,euclidean_st_pt,euclidean_st_pd,euclidean_st_a]\n",
    "    \n",
    "    # Concatenate the features for this chunk with the overall features dataframe\n",
    "    test_features = pd.concat([test_features, chunk_features], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6026cd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_st_pt</th>\n",
       "      <th>cosine_st_pd</th>\n",
       "      <th>cosine_st_a</th>\n",
       "      <th>jaccard_st_pt</th>\n",
       "      <th>jaccard_st_pd</th>\n",
       "      <th>jaccard_st_a</th>\n",
       "      <th>euclidean_st_pt</th>\n",
       "      <th>euclidean_st_pd</th>\n",
       "      <th>euclidean_st_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709927</td>\n",
       "      <td>0.261701</td>\n",
       "      <td>0.115939</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.761673</td>\n",
       "      <td>1.215153</td>\n",
       "      <td>1.329708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273221</td>\n",
       "      <td>0.251018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.205636</td>\n",
       "      <td>1.223913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287774</td>\n",
       "      <td>0.112145</td>\n",
       "      <td>0.067727</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.193504</td>\n",
       "      <td>1.332558</td>\n",
       "      <td>1.365483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.511535</td>\n",
       "      <td>0.199345</td>\n",
       "      <td>0.389144</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.988397</td>\n",
       "      <td>1.265429</td>\n",
       "      <td>1.105311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cosine_st_pt cosine_st_pd cosine_st_a jaccard_st_pt jaccard_st_pd  \\\n",
       "0     0.709927     0.261701    0.115939           0.2      0.015385   \n",
       "1          0.0          0.0         0.0           0.0           0.0   \n",
       "2          0.0     0.273221    0.251018           0.0      0.010526   \n",
       "3     0.287774     0.112145    0.067727      0.083333      0.016393   \n",
       "4     0.511535     0.199345    0.389144           0.2      0.033898   \n",
       "\n",
       "  jaccard_st_a euclidean_st_pt euclidean_st_pd euclidean_st_a  \n",
       "0     0.015625        0.761673        1.215153       1.329708  \n",
       "1          0.0        1.414214        1.414214       1.414214  \n",
       "2     0.007634        1.414214        1.205636       1.223913  \n",
       "3     0.020408        1.193504        1.332558       1.365483  \n",
       "4     0.020619        0.988397        1.265429       1.105311  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "408377ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_st_pt</th>\n",
       "      <th>cosine_st_pd</th>\n",
       "      <th>cosine_st_a</th>\n",
       "      <th>jaccard_st_pt</th>\n",
       "      <th>jaccard_st_pd</th>\n",
       "      <th>jaccard_st_a</th>\n",
       "      <th>euclidean_st_pt</th>\n",
       "      <th>euclidean_st_pd</th>\n",
       "      <th>euclidean_st_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155892</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.299314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155892</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.299314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.733134</td>\n",
       "      <td>0.079048</td>\n",
       "      <td>0.250267</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.73057</td>\n",
       "      <td>1.357167</td>\n",
       "      <td>1.224527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cosine_st_pt cosine_st_pd cosine_st_a jaccard_st_pt jaccard_st_pd  \\\n",
       "0          0.0          0.0         0.0           0.0           0.0   \n",
       "1          0.0          0.0         0.0      0.166667      0.015152   \n",
       "2          0.0          0.0    0.155892      0.166667      0.015152   \n",
       "3          0.0          0.0    0.155892      0.142857      0.014925   \n",
       "4     0.733134     0.079048    0.250267          0.25      0.017544   \n",
       "\n",
       "  jaccard_st_a euclidean_st_pt euclidean_st_pd euclidean_st_a  \n",
       "0          0.0        1.414214        1.414214       1.414214  \n",
       "1     0.015385             1.0             1.0            1.0  \n",
       "2      0.03125        1.414214        1.414214       1.299314  \n",
       "3     0.030769        1.414214        1.414214       1.299314  \n",
       "4     0.020202         0.73057        1.357167       1.224527  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3670c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'id' column from test_x\n",
    "test_id = test_x['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2217c",
   "metadata": {},
   "source": [
    "## 6.1 Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb18e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5051452522698641\n",
      "Validation MSE: 0.2551717258907846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 2: Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train a regression model\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the validation set\n",
    "val_predictions = regression_model.predict(X_val)\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "# Step 5: Make predictions on the test set\n",
    "test_predictions = regression_model.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c9b636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted relevance scores (test_y):\n",
      "[2.11061212 2.34838588 2.28487573 ... 2.91172535 2.34097374 2.31147913]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the predicted relevance scores for the test dataset\n",
    "print(\"Predicted relevance scores (test_y):\")\n",
    "print(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48a40d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'predicted_relevance' column with the predicted values\n",
    "predicted_df['relevance'] = test_predictions\n",
    "\n",
    "\n",
    "predicted_df.to_csv('Info_Sub_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca3607",
   "metadata": {},
   "source": [
    "## 6.2 Support Vector Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4593bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5064921094962158\n",
      "Validation MSE: 0.25653425698192667\n",
      "Predicted relevance scores (test_y):\n",
      "[2.10000573 2.54867674 2.38205306 ... 2.79468371 2.45881095 2.35327494]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 3: Train a Support Vector Regression model\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the validation set\n",
    "val_predictions = svr_model.predict(X_val)\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "test_predictions = svr_model.predict(test_features)\n",
    "\n",
    "# Display the predicted relevance scores for the test dataset\n",
    "print(\"Predicted relevance scores (test_y):\")\n",
    "print(test_predictions)\n",
    "\n",
    "# Create a DataFrame to store the predictions and other relevant columns\n",
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'relevance' column with the predicted values\n",
    "predicted_df['relevance'] = test_predictions\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predicted_df.to_csv('Info_Sub_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c0dd4",
   "metadata": {},
   "source": [
    "## 6.3 Gradient Boosting Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "698c741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.49945415707486435\n",
      "Validation MSE: 0.24945445501936328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Step 3: Train a Gradient Boosting Regression model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the validation set\n",
    "val_predictions_gb = gb_model.predict(X_val)\n",
    "val_rmse_gb = mean_squared_error(y_val, val_predictions_gb, squared=False)\n",
    "val_mse = mean_squared_error(y_val, val_predictions_gb)\n",
    "print(\"Validation RMSE:\", val_rmse_gb)\n",
    "print(\"Validation MSE:\", val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01dca1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted relevance scores using Gradient Boosting:\n",
      "[1.98612298 2.4643741  2.32976787 ... 2.68401974 2.32771558 2.29819585]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Make predictions on the test set\n",
    "test_predictions_gb = gb_model.predict(test_features)\n",
    "\n",
    "# Display the predicted relevance scores for the test dataset\n",
    "print(\"Predicted relevance scores using Gradient Boosting:\")\n",
    "print(test_predictions_gb)\n",
    "\n",
    "# Create a DataFrame to store the predictions and other relevant columns\n",
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'relevance' column with the predicted values\n",
    "predicted_df['relevance'] = test_predictions_gb\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predicted_df.to_csv('Info_Sub_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f313d",
   "metadata": {},
   "source": [
    "## 6.4 Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5221925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5111435574936236\n",
      "Validation MSE 0.2612677363672373\n",
      "Predicted relevance scores using Random Forest Regressor:\n",
      "[1.98074005 2.6632     2.6839     ... 2.66536667 2.4139     2.2197    ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 3: Train a Random Forest Regression model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the validation set\n",
    "val_predictions_rf = rf_model.predict(X_val)\n",
    "val_rmse_rf = mean_squared_error(y_val, val_predictions_rf, squared=False)\n",
    "val_mse = mean_squared_error(y_val, val_predictions_rf)\n",
    "print(\"Validation RMSE:\", val_rmse_rf)\n",
    "print(\"Validation MSE\", val_mse)\n",
    "      \n",
    "test_predictions_rf = rf_model.predict(test_features)\n",
    "\n",
    "# Display the predicted relevance scores for the test dataset\n",
    "print(\"Predicted relevance scores using Random Forest Regressor:\")\n",
    "print(test_predictions_rf)\n",
    "\n",
    "# Create a DataFrame to store the predictions and other relevant columns\n",
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'relevance' column with the predicted values\n",
    "predicted_df['relevance'] = test_predictions_rf\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predicted_df.to_csv('Info_Sub_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2320678",
   "metadata": {},
   "source": [
    "## 6.5 Decision Tree Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b7533a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.6818088512402047\n",
      "Validation MSE: 0.4648633096294877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create the model\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = dt_model.predict(X_val)\n",
    "# Calculate RMSE and MSE on the validation set\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.predict(test_features)\n",
    "\n",
    "# Create a DataFrame to store the predictions and other relevant columns\n",
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'relevance' column with the predicted values\n",
    "predicted_df['relevance'] = dt_predictions\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predicted_df.to_csv('Info_Sub_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3963a02f",
   "metadata": {},
   "source": [
    "## 6.6 KNeighnors Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cadeb862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5422044426424125\n",
      "Validation MSE: 0.2939856576211692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create the model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "val_predictions = knn_model.predict(X_val)\n",
    "# Calculate RMSE and MSE on the validation set\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "\n",
    "# Make predictions\n",
    "knn_predictions = knn_model.predict(test_features)\n",
    "\n",
    "# Create a DataFrame to store the predictions and other relevant columns\n",
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'relevance' column with the predicted values\n",
    "predicted_df['relevance'] = knn_predictions\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predicted_df.to_csv('Info_Sub_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcde6f8",
   "metadata": {},
   "source": [
    "## 6.7 XGBoost Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25f214ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5046074768620744\n",
      "Validation MSE: 0.254628705705109\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert all columns to float\n",
    "# Convert all columns to float\n",
    "cols_to_convert = ['cosine_st_pt', 'cosine_st_pd', 'cosine_st_a', \n",
    "                   'jaccard_st_pt', 'jaccard_st_pd', 'jaccard_st_a', \n",
    "                   'euclidean_st_pt', 'euclidean_st_pd', 'euclidean_st_a']\n",
    "\n",
    "train_features[cols_to_convert] = train_features[cols_to_convert].astype(float)\n",
    "# Convert train_y to float\n",
    "train_y = train_y.astype(float)\n",
    "test_features[cols_to_convert] = test_features[cols_to_convert].astype(float)\n",
    "\n",
    "X_train_xg, X_val_xg, y_train_xg, y_val_xg = train_test_split(train_features, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_xg, y_train_xg)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = xgb_model.predict(X_val_xg)\n",
    "\n",
    "# Calculate RMSE and MSE on the validation set\n",
    "val_rmse = mean_squared_error(y_val_xg, val_predictions, squared=False)\n",
    "val_mse = mean_squared_error(y_val_xg, val_predictions)\n",
    "\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "\n",
    "xgb_predictions = xgb_model.predict(test_features)\n",
    "\n",
    "# Create a DataFrame to store the predictions and other relevant columns\n",
    "predicted_df = pd.DataFrame(columns=['id', 'relevance'])\n",
    "\n",
    "# Fill in the 'id' column with the extracted 'id' values\n",
    "predicted_df['id'] = test_id\n",
    "\n",
    "# Fill in the 'relevance' column with the predicted values\n",
    "predicted_df['relevance'] = xgb_predictions\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predicted_df.to_csv('xgb_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d77de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
